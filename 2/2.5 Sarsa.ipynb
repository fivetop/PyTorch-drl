{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7824fda9",
   "metadata": {},
   "source": [
    "## 2.5 Sarsa 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ad24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구현에 사용할 패키지 임포트하기\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d02022b",
   "metadata": {},
   "source": [
    "### 초기 상태의 미로 모습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42bbc382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 전체 그림의 크기 및 그림을 나타내는 변수 선언\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# 붉은 벽 그리기\n",
    "plt.plot([1, 1], [0, 1], color='red', linewidth=2)\n",
    "plt.plot([1, 2], [2, 2], color='red', linewidth=2)\n",
    "plt.plot([2, 2], [2, 1], color='red', linewidth=2)\n",
    "plt.plot([2, 3], [1, 1], color='red', linewidth=2)\n",
    "\n",
    "# 각 좌표의 상태를 의미하는 문자열(S0~S8) 표시\n",
    "plt.text(0.5, 2.5, 'S0', size=14, ha='center')\n",
    "plt.text(1.5, 2.5, 'S1', size=14, ha='center')\n",
    "plt.text(2.5, 2.5, 'S2', size=14, ha='center')\n",
    "plt.text(0.5, 1.5, 'S3', size=14, ha='center')\n",
    "plt.text(1.5, 1.5, 'S4', size=14, ha='center')\n",
    "plt.text(2.5, 1.5, 'S5', size=14, ha='center')\n",
    "plt.text(0.5, 0.5, 'S6', size=14, ha='center')\n",
    "plt.text(1.5, 0.5, 'S7', size=14, ha='center')\n",
    "plt.text(2.5, 0.5, 'S8', size=14, ha='center')\n",
    "plt.text(0.5, 2.3, 'START', ha='center')\n",
    "plt.text(2.5, 0.3, 'GOAL', ha='center')\n",
    "\n",
    "# 그림을 그릴 범위 및 눈금 제거 설정\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(0, 3)\n",
    "plt.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                labelbottom=False, right=False, left=False, labelleft=False)\n",
    "\n",
    "# S0에 녹색 원으로 현재 위치를 표시\n",
    "line, = ax.plot([0.5], [2.5], marker=\"o\", color='g', markersize=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab8231e",
   "metadata": {},
   "source": [
    "### 정책을 결정하는 파라미터의 초깃값 theta_0을 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5338ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 줄은 상태 0~7, 열은 행동방향(상,우,하,좌 순)를 나타낸다\n",
    "theta_0 = np.array([[np.nan, 1, 1, np.nan],  # s0\n",
    "                    [np.nan, 1, np.nan, 1],  # s1\n",
    "                    [np.nan, np.nan, 1, 1],  # s2\n",
    "                    [1, 1, 1, np.nan],  # s3\n",
    "                    [np.nan, np.nan, 1, 1],  # s4\n",
    "                    [1, np.nan, np.nan, np.nan],  # s5\n",
    "                    [1, np.nan, np.nan, np.nan],  # s6\n",
    "                    [1, 1, np.nan, np.nan],  # s7、※s8은 목표지점이므로 정책이 없다\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f949befc",
   "metadata": {},
   "source": [
    "### 정책 파라미터 theta_0을 무작위 행동 정책 pi로 변환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aecc935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_convert_into_pi_from_theta(theta):\n",
    "    '''단순 비율 계산'''\n",
    "    \n",
    "    [m,n] = theta.shape # theta의 행렬 크기를 구함\n",
    "    pi = np.zeros((m,n))\n",
    "    for i in range(0,m):\n",
    "        pi[i,:] = theta[i,:] / np.nansum(theta[i,:]) # 비율 계산\n",
    "    \n",
    "    pi = np.nan_to_num(pi) # nan을 0으로 변환\n",
    "    \n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c0e2b4",
   "metadata": {},
   "source": [
    "### 무작위 행동정책 pi_0을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e773870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.5       , 0.5       , 0.        ],\n",
       "       [0.        , 0.5       , 0.        , 0.5       ],\n",
       "       [0.        , 0.        , 0.5       , 0.5       ],\n",
       "       [0.33333333, 0.33333333, 0.33333333, 0.        ],\n",
       "       [0.        , 0.        , 0.5       , 0.5       ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 0.5       , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_0 = simple_convert_into_pi_from_theta(theta_0)\n",
    "pi_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa99168",
   "metadata": {},
   "source": [
    "### 행동가치 함수 Q의 초기 상태\n",
    "Q(s,a) : 행은 상태s, 열은 행동 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdf17570",
   "metadata": {},
   "outputs": [],
   "source": [
    "[a, b] = theta_0.shape # 열과 행의 개수를 변수 a, b에 저장\n",
    "Q = np.random.rand(a, b) * theta_0\n",
    "# * theta_0으로 요소 단위 곱셈을 수행, Q에서 벽 방향으로 이동하는 행동에는 nan을 부여"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a824b251",
   "metadata": {},
   "source": [
    "### ε-greedy 알고리즘 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6c0f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행동을 결정하는 함수 get_action\n",
    "def get_action(s, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "    \n",
    "    # 행동을 결정\n",
    "    if np.random.rand() < epsilon:\n",
    "        # 확률 ε로 무작위 행동을 선택함\n",
    "        next_direction = np.random.choice(direction, p=pi_0[s, :])\n",
    "    else:\n",
    "        # Q값이 최대가 되는 행동을 선택함\n",
    "        next_direction = direction[np.nanargmax(Q[s, :])]\n",
    "    \n",
    "    # 행동을 인덱스로 변환\n",
    "    if next_direction == \"up\":\n",
    "        action = 0\n",
    "    elif next_direction == \"right\":\n",
    "        action = 1\n",
    "    elif next_direction == \"down\":\n",
    "        action = 2\n",
    "    elif next_direction == \"left\":\n",
    "        action = 3\n",
    "        \n",
    "    return action\n",
    "\n",
    "# 행동을 인자로 받아 다음 상태를 구하는 함수 get_s_next\n",
    "def get_s_next(s, a, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "    next_direction = direction[a] # 행동 a의 방향\n",
    "    \n",
    "    # 행동으로 다음 상태를 결정\n",
    "    if next_direction == \"up\":\n",
    "        s_next = s - 3 # 위로 이동하면 상태값이 3만큼 줄어든다.\n",
    "    elif next_direction == \"right\":\n",
    "        s_next = s + 1 # 오른쪽으로 이동하면 상태값이 1만큼 늘어난다.\n",
    "    elif next_direction == \"down\":\n",
    "        s_next = s +3\n",
    "    elif next_direction == \"left\":\n",
    "        s_next = s -1\n",
    "    \n",
    "    return s_next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a23c5a",
   "metadata": {},
   "source": [
    "### Sarsa 알고리즘으로 행동가치 함수 Q를 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9656c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sarsa(s, a, r, s_next, a_next, Q, eta, gamma):\n",
    "    if s_next == 8: # 목표 지점에 도달한 경우\n",
    "        Q[s, a] = Q[s, a] + eta * (r - Q[s, a])\n",
    "    \n",
    "    else:\n",
    "        Q[s, a] = Q[s, a] + eta * (r + gamma * Q[s_next, a_next] - Q[s, a])\n",
    "        \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce5e8a9",
   "metadata": {},
   "source": [
    "## Sarsa로 미로찾기 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84961938",
   "metadata": {},
   "source": [
    "### Sarsa 알고리즘으로 미로를 빠져나오는 함수, 상태 및 행동 그리고 Q값의 히스토리를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af67159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi):\n",
    "    s = 0 # 시작 지점\n",
    "    a = a_next = get_action(s, Q, epsilon, pi) # 첫 번째 행동\n",
    "    s_a_history = [[0, np.nan]] # 에이전트의 행동 및 상태의 히스토리를 기록하는 리스트\n",
    "    \n",
    "    while(1): # 목표 지점에 이를 때까지 반복\n",
    "        a = a_next # 행동 결정\n",
    "        \n",
    "        s_a_history[-1][1] = a # 현재 상태(마지막이므로 인덱스가 -1)를 히스토리에 추가\n",
    "        \n",
    "        s_next = get_s_next(s, a, Q, epsilon, pi) # 다음 단계의 상태를 구함\n",
    "        \n",
    "        s_a_history.append([s_next, np.nan]) # 다음 상태를 히스토리에 추가, 행동은 아직 알 수 없으므로 nan으로 둔다.\n",
    "        \n",
    "        # 보상을 부여하고 다음 행동을 계산\n",
    "        if s_next == 8:\n",
    "            r = 1 # 목표 지점에 도달했다면 보상을 부여\n",
    "            a_next = np.nan\n",
    "        else:\n",
    "            r = 0\n",
    "            a_next = get_action(s_next, Q, epsilon, pi) # 다음 행동 a_next를 계산\n",
    "            \n",
    "        # 가치 함수를 수정\n",
    "        Q = Sarsa(s, a, r, s_next, a_next, Q, eta, gamma)\n",
    "        \n",
    "        # 종료 여부 판정\n",
    "        if s_next == 8:\n",
    "            break\n",
    "        else:\n",
    "            s = s_next\n",
    "    \n",
    "    return [s_a_history, Q]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcfc5b8",
   "metadata": {},
   "source": [
    "### Sarsa 알고리즘으로 미로 빠져나오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f79fcc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에피소드: 1\n",
      "0.012132653781671388\n",
      "목표 지점에 이르기까지 걸린 단계 수는 6단계입니다\n",
      "에피소드: 2\n",
      "0.16213679647766854\n",
      "목표 지점에 이르기까지 걸린 단계 수는 10단계입니다\n",
      "에피소드: 3\n",
      "0.001923330734588613\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 4\n",
      "0.03202885315975634\n",
      "목표 지점에 이르기까지 걸린 단계 수는 6단계입니다\n",
      "에피소드: 5\n",
      "0.005120191681041053\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 6\n",
      "0.00418963238917236\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 7\n",
      "0.0034195871980656767\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 8\n",
      "0.002784717432029793\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 9\n",
      "0.002263399257603993\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 10\n",
      "0.0019726955683211367\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 11\n",
      "0.0019439873182957035\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 12\n",
      "0.0019244221286573993\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 13\n",
      "0.0019032284062556748\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 14\n",
      "0.0018795477593777088\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 15\n",
      "0.0018528467269883775\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 16\n",
      "0.001822846780611953\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 17\n",
      "0.001789466426040387\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 18\n",
      "0.001752773550941944\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 19\n",
      "0.0017129464275219553\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 20\n",
      "0.0016702420070756618\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 21\n",
      "0.0016249703401369775\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 22\n",
      "0.0015774741259865221\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 23\n",
      "0.0015281125420214536\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 24\n",
      "0.001477248629979555\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 25\n",
      "0.0014252396249149202\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 26\n",
      "0.0013724297064683366\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 27\n",
      "0.0013191447323990246\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 28\n",
      "0.001265688583322988\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 29\n",
      "0.0012123408066585517\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 30\n",
      "0.0011593552982825939\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 31\n",
      "0.0011069598034996186\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 32\n",
      "0.0010553560556434416\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 33\n",
      "0.001004720401851733\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 34\n",
      "0.000955204792040254\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 35\n",
      "0.0009069380295261276\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 36\n",
      "0.0008600272006705767\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 37\n",
      "0.0008145592168511406\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 38\n",
      "0.000770602415445798\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 39\n",
      "0.0007282081776917027\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 40\n",
      "0.000687412530601339\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 41\n",
      "0.0006482377078476098\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 42\n",
      "0.0006106936509030492\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 43\n",
      "0.0005747794369623804\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 44\n",
      "0.0005404846244312367\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 45\n",
      "0.0005077905102300884\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 46\n",
      "0.00047667129591721924\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 47\n",
      "0.0004470951618343877\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 48\n",
      "0.00041902525018744363\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 49\n",
      "0.0003924205592924501\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 50\n",
      "0.00036723675219973995\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 51\n",
      "0.00034342688362465346\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 52\n",
      "0.00032094204960664285\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 53\n",
      "0.000299731964631178\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 54\n",
      "0.0002797454711150893\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 55\n",
      "0.00026093098621327027\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 56\n",
      "0.00024323689086669376\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 57\n",
      "0.00022661186589989502\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 58\n",
      "0.0002110051798275281\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 59\n",
      "0.00019636693281765982\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 60\n",
      "0.0001826482610489677\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 61\n",
      "0.00016980150544199102\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 62\n",
      "0.0001577803485049989\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 63\n",
      "0.00014653992276691952\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 64\n",
      "0.00013603689402119645\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 65\n",
      "0.0001262295223494192\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 66\n",
      "0.0001170777036485493\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 67\n",
      "0.00010854299415574697\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 68\n",
      "0.00010058862023165638\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 69\n",
      "9.317947546338967e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 70\n",
      "8.628210693617522e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 71\n",
      "7.98646923484414e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 72\n",
      "7.389700946136557e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 73\n",
      "6.835039922237218e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 74\n",
      "6.319772374541177e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 75\n",
      "5.8413320202066465e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 76\n",
      "5.397295154951909e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 77\n",
      "4.9853754908624204e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 78\n",
      "4.6034188299626244e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 79\n",
      "4.2493976356583474e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 80\n",
      "3.9214055549963156e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 81\n",
      "3.617651937259936e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 82\n",
      "3.336456388103315e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 83\n",
      "3.076243391697542e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 84\n",
      "2.835537028367252e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 85\n",
      "2.612955810099571e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 86\n",
      "2.407207652510568e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 87\n",
      "2.217084997346852e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 88\n",
      "2.041460097168546e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 89\n",
      "1.8792804704292898e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 90\n",
      "1.7295645327930487e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 91\n",
      "1.5913974083181515e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 92\n",
      "1.4639269225846796e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 93\n",
      "1.346359777876227e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 94\n",
      "1.237957909250298e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 95\n",
      "1.1380350195211442e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 96\n",
      "1.045953289680046e-05\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 97\n",
      "9.611202610892988e-06\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 98\n",
      "8.829858847425598e-06\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 99\n",
      "8.110397325511443e-06\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 100\n",
      "7.448083653605053e-06\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1 # 학습률\n",
    "gamma = 0.9 # 시간할인율\n",
    "epsilon = 0.5 # ε-greedy 알고리즘 epsilon 초깃값\n",
    "v = np.nanmax(Q, axis=1) # 각 상태마다 가치의 최댓값을 계산\n",
    "is_continue = True\n",
    "episode = 1\n",
    "\n",
    "while is_continue:\n",
    "    print(\"에피소드: \" + str(episode))\n",
    "    \n",
    "    # ε 값을 조금씩 감소시킴\n",
    "    epsilon = epsilon / 2\n",
    "    \n",
    "    # Sarsa 알고리즘으로 미로를 빠져나온 후, 결과로 나온 행동 히스토리와 Q값을 변수에 저장\n",
    "    [s_a_history, Q] = goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi_0)\n",
    "    \n",
    "    # 상태가치의 변화\n",
    "    new_v = np.nanmax(Q, axis=1) # 각 상태마다 행동가치와 최댓값을 계산\n",
    "    print(np.sum(np.abs(new_v - v))) # 상태가치 함수와 변화를 출력\n",
    "    v = new_v\n",
    "    \n",
    "    print(\"목표 지점에 이르기까지 걸린 단계 수는 \" + str(len(s_a_history) - 1) + \"단계입니다\")\n",
    "    \n",
    "    # 100 에피소드 반복\n",
    "    episode = episode + 1\n",
    "    if episode > 100:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "de47f5c92c0ee6f12a59a5613ac5feff6aab19ddff207ba0b3964cced08c4ccc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
